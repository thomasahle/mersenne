%! TEX root = ../mersenne.tex
\section{Introduction}

\begin{figure}
	\centering
	\begin{tikzpicture}[darkstyle/.style={circle,draw,fill=gray!40,minimum size=20}]
		\newcommand*{\figb}{8}
		% The red box
		\draw[pattern=north west lines, pattern color=red] (0,0) rectangle (\figb,1);
		% Horizontal lines
		\foreach \y in {0,...,6}
		\draw (0, \y) -- (\figb, \y);
		% Vertical lines
		\foreach \x in {0,...,\figb}
		\draw (\x, 0) -- (\x, 6);
		% Most of the numbers
		\pgfmathsetmacro{\figbthree}{\figb - 3}
		\pgfmathsetmacro{\figbtwo}{\figb - 2}
		\pgfmathsetmacro{\figbone}{\figb - 1}
		\foreach \y in {0,...,2}
		\foreach \x in {0,...,\figbthree}
		\node [draw=none] at (.5+\x,.5+\y) {1};
		\foreach \x in {\figbthree,...,\figbone}
		\node [draw=none] at (.5+\x,.5+3) {.};
		\foreach \y in {4,...,5}
		\foreach \x in {0,...,\figbtwo}
		\node [draw=none] at (.5+\x,.5+\y) {0};
		% The rest of the numbers
		\node [draw=none] at (.5+\figb-1,.5+0) {1};
		\node [draw=none] at (.5+\figb-2,.5+0) {1};
		\node [draw=none] at (.5+\figb-1,.5+1) {0};
		\node [draw=none] at (.5+\figb-2,.5+1) {1};
		\node [draw=none] at (.5+\figb-1,.5+2) {1};
		\node [draw=none] at (.5+\figb-2,.5+2) {0};
		\node [draw=none] at (.5+\figb-1,.5+4) {1};
		\node [draw=none] at (.5+\figb-1,.5+5) {0};
	\end{tikzpicture}
	\caption{The output of a random polynomial modulo $p=2^b-1$ is uniformly distributed in $[p]$, so each bit has the same distribution, which is only $1/p$ biased towards 0.}
	\label{fig:bits}
\end{figure}

The classic way to implement $k$-universal hashing is to use a random degree $(k-1)$-polynomial over a finite field \cite{wegman81kwise}.
Mersenne primes, which are prime numbers on the form $2^b-1$, have been used to implement finite fields efficiently for more than 40 years using standard portable code \cite{carter77universal}.

The speed of hashing is important because it is often an inner-loop
bottle-neck in data analysis. A good example is when hashing is used
in the sketching of high volume data streams, such as traffic through
an Internet router, and then this speed is critical to keep up with
the stream. A running example in this paper is the classic second
moment estimation using 4-universal hashing in count sketches
\cite{charikar04count-sketch}.
Count Sketches are linear maps that statistically preserve the Euclidean norm.
They are also popular in machine learning under the name
``Feature Hashing''~\cite{moody1989fast,weinberger2009feature}.

In this paper, we argue that uniform random values from Mersenne prime fields
%with prime $p=2^b-1$
are not only fast to compute but
\emph{have special advantages different from any other field.}
While it is natural to consider values mod $p=2^b-1$ as ``nearly'' uniform $b$-bit strings
(see \Cref{fig:bits}),
we show that the small bias in our hash values can usually be turned into an advantage.
In particular our analysis justify splitting single hash values into two or more for a significant computational speed-up, what we call the ``Two for one'' trick.

We also show that while the $1/p$ bias of such strings would usually result in relative errors of order $n/p$ for Count Sketch, a specialized analysis yields relative errors of just $n/p^2$.
The analysis is based on simple moments, and give similar improvements for any algorithm analyzed this way.
Loosely speaking, this means that we for a desired small error can reduce
the bit-length of the primes to less than half. This saves not only
space, it means that we can speed up the multiplications
with a factor of 2.

Finally we provide a fast, simple and branch-free algorithm for division and modulus with Mersenne primes.
Contrasting our analytic work, this code generalizes to so-called Pseudo-Mersenne primes~\cite{van2014encyclopedia} of the form $p=2^b-c$ for small $c$.
Our new code is simpler and faster than the classical algorithm of Crandall~\cite{crandall1992method}.

We provide experiments of both algorithms in \Cref{sec:experiments}.
For the rest of the introduction we will give a more detailed review of the new results.

\subsection{Hashing uniformly into b bits}\label{sec:b-bit?}
A main point in this paper is that having hash values uniform in $[2^b-1]=\{0,\dots,2^b-2\}$
is almost as good as having uniform $b$-bit strings, but of course,
it would be even better if we just had uniform $b$-bit strings.

We do have the fast multiply-shift scheme of Dietzfelbinger~\cite{dietzfel96universal}, which directly gives 2-universal
hashing from $b$-bit strings to $\ell$-bit strings, but for $k>2$,
there is no such fast $k$-universal hashing scheme that
can be implemented with standard portable code.

More recently it has been suggested to use carry-less multiplication
for $k$-universal hashing into bit strings (see, e.g., Lemire
\cite{lemire2014strongly}) but contrasting the hashing with Mersenne primes,
this is less standard (takes some work to get it to run on different
computers) and slower (by about 30-50\% for larger $k$ on the computers we tested in \Cref{sec:experiments}).
Moreover, the code for different bit-lengths $b$ is quite different
because we need quite different irreducible polynomials.

Another alternative is to use tabulation based methods which are fast
but use a lot of space \cite{Siegel04,Tho13:simple-simple}, that is,
space $s=2^{\Omega(b)}$ to calculate $k$-universal hash function in
constant time from $b$-bit keys to $\ell$-bit hash values. The large
space can be problematic.

A classic example where constant space hash functions are needed is in static two-level hash functions \cite{FKS84}.
To store n keys with constant access time, you use $n$ second-level hash tables, each with its own hash function.
Another example is small sketches such as the Count Sketch \cite{charikar04count-sketch} discussed in this paper.
Here we may want to store the hash function as part of the sketch, e.g., to query the value of a given key.
Then the hash value has to be directly computable from the small representation, ruling out tabulation based methods (see further explanation at the end of \Cref{sec:count-sketch}).

It can thus be problematic to get efficient $k$-universal hashing directly into
$b$-bit strings, and this is why we in this paper analyse the
hash values from Mersenne prime fields that are much easier to generate.

\subsection{Polynomial hashing using Mersenne primes}

Before discussing the special properties of Mersenne primes in algorithm analysis, we show how they are classically used to do fast field computations, and propose a new simple algorithm for further speed-ups in the hashing case.

The definition of $k$-universal hashing
goes back to Carter and Wegman~\cite{wegman81kwise}.
\begin{definition}
	A random hash function $h:U\to R$ is $k$-universal if for $k$
	distinct keys $x_0,\ldots,x_{k-1}\in U$, the $k$-tuple
	$(h(x_0),\ldots,h(x_{k-1}))$ is uniform in $R^k$.
\end{definition}
\noindent
Note that the definition also implies the values
$h(x_0),\ldots,h(x_{k-1})$ are independent.
A very similar concept is that of $k$-independence, which has only this requirement but doesn't include that values must be uniform.

For $k>2$ the standard $k$-universal hash function is uniformly random degree-$(k-1)$ polynomial over a prime field
$\Z_p$, that is, we pick a uniformly random vector
$\vec a=(a_0,\ldots,a_{k-1})\in \Z_p^k$ of $k$ coefficients, and define
$h_{\vec a}:[p]\to[p]$,
\footnote{ We use the notation $[s]=\{0,\ldots,s-1\}$.  }
by
\[h_{\vec a}(x)=\sum_{i\in[k]}a_i x^i \mod p.\]
%
Given a desired key domain $[u]$ and range $[r]$ for the hash values, we pick
$p\geq \max\{u,r\}$ and define
$h^r_{\vec a}:[u]\to[r]$ by
\[h^r_{\vec a}(x)=h_{\vec a}(x)\bmod r.\]
The  hash values of $k$ distinct keys remain independent while staying as close as possible to the uniform distribution on $[r]$.
(This will turn out to be very important.)

In terms of speed, the main bottleneck in the above approach is the mod operations.
If we assume $r=2^\ell$, the mod $r$ operation above can be replaced by a binary {\sc and} (\texttt{\&}): $x \bmod r = x \andtt r-1$.
Similarly, Carter and Wegman \cite{carter77universal} used a
Mersenne prime $p=2^b-1$,\footnote{e.g., $p=2^{61}-1$ for hashing 32-bit keys or
$p=2^{89}-1$ for hashing 64-bit keys.}
to speed up the computation of the (mod $p$) operations:
\begin{equation}
	y% \bmod (2^b-1)
	\equiv y - \floor{y/2^b}(2^b-1)
	= (y\bmod 2^{b}) + \floor{y/2^b}
	%   \equiv (y \andtt p) + (y \rs b)
	\pmod {p}.
	\label{eq:Mersenne}
\end{equation}
Again allowing us to use the very fast bit-wise {\sc and} ($\andtt$) and the right-shift ($\rs$),
instead of the expensive modulo operation.

Of course, \eqref{eq:Mersenne} only reduces $y$ to an equivalent value mod $p$, not to the smallest one, which is what we usually want.
For this reason one typically adds a test ``if $y \ge p$ then $y \gets y - p$''.
We show an implementation in \Cref{alg:Mersenne} below with one further improvement:
By assuming that $p=2^b-1\geq 2u-1$
(which is automatically satisfied in the typical case where $u$ is a power
of two, e.g., $2^{32}$ or $2^{64}$)
we can get away with only doing this test once, rather than at every loop.
Note the proof by loop invariant in the comments.

\begin{algorithm}[H]
	\caption{
	For $x\in [u]$, prime $p=2^b-1\geq 2u-1$,
	and $\vec a=(a_0,\ldots,a_{k-1})\in[p]^k$,
	computes $y=h_{\vec a}(x)=\sum_{i\in[k]}a_i x^i\mod p$.
	}\label{alg:Mersenne}
	\begin{algorithmic}
		\State $y\gets a_{k-1}$
		\For{$i=q-2,\ldots,0$}
		\Comment{Invariant: $\quad y<2p$}

		\State $y\gets y*x+a_i$
		\Comment{$\quad y<2p(u-1)+(p-1)<(2u-1)p\leq p^2$}

		\State $y\gets (y\andtt p)+(y\rs b)$
		\Comment{$\quad y<p+p^2/2^b<2p$}
		\EndFor
		\If{$y\geq p$}
		\State $y\gets y-p$
		\Comment{$y<p$}
		\EndIf
		%\State \Return $y$
	\end{algorithmic}
\end{algorithm}


In \Cref{subsec:intro-division} we will give one further improvement to \Cref{alg:Mersenne}.
In the next sections we will argue that Mersenne primes are not only fast, but have special properties not found in other finite fields.

%The main point of this paper is our note from before, that the values hashed to $[r]$ are not completely uniform, as they would have been if $p=2^b$ was a prime.
%It turns out that with a novel analysis, bits from Mersenne primes are actually
%almost as good as if
%they were uniformly distributed $b$-bit strings (we are only missing
%the all \texttt{1}s value $2^b-1$). 


\subsubsection{Selecting arbitrary bits}\label{sec:power-of-two}
If we had b uniform bits, we could partition them any way weâ€™d like and get smaller independent
strings of uniform random bits. The first property of random values modulo Mersenne primes
we discuss is what happens when the same thing is done on a random value in $[2^b - 1]$ instead.

More formally, let $\mu:[2^b]\to[2^\ell]$ be any map that selects
$\ell$ distinct bits, that is, for some $0\leq j_1<\cdots<j_{\ell}<b$,
$\mu(y)=y_{j_1}\cdots y_{j_\ell}$. For example, if $j_i=i-1$, then we
are selecting the most significant bits, and then $\mu$ can be
implemented as $y\mapsto y\rs (b-\ell)$. Alternatively, if $j_i=b-i$,
then we are selecting the least significant bits, and then $\mu$ can
be implemented as $y\mapsto y\andtt (2^\ell-1)=y\andtt (r-1)$.


We assume a $k$-universal hash function $h:[u]\to[p]$, e.g.,
the one from \Cref{alg:Mersenne}. To get hash values in $[r]$,
we use $\mu\circ h$. Since $\mu$ is deterministic,
the hash values of up to $k$ distinct keys remain
independent with $\mu\circ h$. The issue is that hash values from
$\mu\circ h$ are not quite uniform in $[r]$.

Recall that for any key $x$, we have $h(x)$ uniformly distributed in $[2^b-1]$.
This is the uniform distribution on $b$-bit strings except that we are
missing $p=2^b-1$. Now $p$ is the all \texttt{1}s, and
$\mu(p) = r-1$.
Therefore
\begin{align}
	\text{for $i < r-1$,}\quad
	\Pr[\mu(h(x))=i]
	 & =\lceil p/r\rceil/p
	=((p+1)/r)/p
	=(1+1/p)/r
	\label{eq:coll-ell<r-1}
	\\
	\text{and}\quad
	\Pr[\mu(h(x))=r-1]
	 & =\lfloor p/r\rfloor/p=((p+1-r)/r)/p
	=(1-(r-1)/p)/r.
	\label{eq:coll-ell=r-1}
\end{align}
Thus $\Pr[\mu(h(x))=i]\leq (1+1/p)/r$ for all $i\in[r]$.
This upper-bound only has a relative error of $1/p$ from the uniform $1/r$.

Combining \eqref{eq:coll-ell<r-1} and \eqref{eq:coll-ell=r-1} with
pairwise independence, for any distinct keys $x,y\in [u]$, we show that the
collision probability is bounded
\begin{align}
	\Pr[\mu(h(x))=\mu(h(y))]
	 & =(r-1)((1+1/p)/r)^2+((1-(r-1)r/p)/r)^2 \nonumber
	%\\&= \frac{r +(r^2-r)/p^2}{r^2}
	\\&=(1+(r-1)/p^2)/r
	%\\& <(1+r/p^2)/r
	.\label{eq:coll}
\end{align}
Thus the relative error $r/p^2$ is small as long as $p$ is large.

\paragraph{The problem with non-Mersenne Primes}

Suppose $c\neq 1$ and we want to select arbitrary bits like in the arguments above.
If we pick the least significant bits we get a generic upper bound of $(1+c/p)/r$, which is not too bad for small $c$.
Here there is no conceptual difference to our Mersenne results.

However take the opposite extreme where
we pick just the one most significant bit
and $c=2^{b-1}-1$ (so $p=2^{b-1}+1$, a Fermat prime).
That bit is $0$ with probability $1-1/p$ and 1 only with probability $p$ -- virtually a constant.
We might try to fix this by xoring the output with a random number from $[2^b]$ (or add $C\in[2^b]$ and take mod $2^b$), but that will only make the bits uniform, not actually dependent on the key.
Thus if we hash two keys, $x_1$ and $x_2$, mod $2^{b-1}+1$ and take the top bit from each one, \emph{they will nearly always be the same, independent of whether $x_1=x_2$}.

More realistically,
say we pick the $\ell$ most significant bits
and $c\leq 2^{b-1}-2^{b-\ell}$, then $2^{b-\ell}$ elements from
$[p]$ map to $0$ while only $\max\{0,2^{b-\ell}-c\}$
map to the all \texttt{1}s.
More concretely, take $\ell=b/2$ and $c=2^{b/2}\approx\sqrt{p}$ (typical for generalized Mersenne primes) \emph{then the top $\ell$ bits hit the all \texttt{1}s with 0 probability}, while the all \texttt{0}s is twice as common as the remaining values.


\subsection{Two-for-one hash functions in second moment estimation}
In this section, we discuss how we can get several hash functions for
the price of one, and apply the idea to second moment estimation using
Count Sketches \cite{charikar04count-sketch}.

Suppose we had a $k$-universal hash function into $b$-bit strings.
We note that using standard programming languages such as C, we have
no simple and efficient method of computing such hash
functions when $k>2$. However, later we will argue that polynomial
hashing using a Mersenne prime $2^b-1$ delivers a better-than-expected
approximation.

Let $h:U\to [2^b]$ be $k$-universal. By definition this
means that if we have $j\leq k$ distinct keys $x_0,\ldots,x_{j - 1}$, then
$(h(x_0),\ldots,h(x_{j - 1}))$ is uniform in $[2^b]^j\equiv [2]^{bj}$,
so this means that \emph{all} the bits in $h(x_0),\ldots,h(x_{j - 1})$ are
independent and uniform. We can use this to split our $b$-bit hash
values into smaller segments, and sometimes use them as if
they were the output of universally computed hash functions.

We illustrate this idea below in the context of the second moment estimation.
For this purpose the ``split'' we will be considering is into the first bit and the remaining bits.

\subsubsection{Second moment estimation}\label{sec:count-sketch}
We now review the second moment estimation of streams based on Count Sketches \cite{charikar04count-sketch} (which are based on the
celebrated second moment AMS-estimator from \cite{alon96frequency}.)

The basic setup is as follows:
For keys in $[u]$ and integer values in $\Z$, we are given a stream of key/value $(x_0,\Delta_0),\ldots, (x_{n-1},\Delta_{n-1})\in [u]\times\Z$. The
total value of key $x\in[u]$ is
\[f_x=\sum_{i\in[n],x_i=x} \Delta_i.\]
We let $n\leq u$ be  the number of non-zero values
$f_x\neq 0$, $x\in [u]$. Often $n$ is much smaller than $u$.
We define the $m$th moment $F_m = \sum_{x\in [u]}f_y^m$. The goal here is to
estimate the second moment $F_2 = \sum_{x\in [u]}f_x^2=\|f\|^2_2$.

\begin{algorithm}[H]
	\caption{\label{alg:count-sketch} Count Sketch. Uses a
	vector/array $C$ of $r$ integers and two independent
	4-universal hash functions $i:[u]\to[r]$ and $s:[u]\to\{-1,1\}$.
	}
	\begin{algorithmic}
		\Procedure{Initialize}{}
		\State For $i\in[t]$, set $C[i]\gets 0$.
		\EndProcedure
		\Procedure{Process}{$x, \Delta$}
		\State $C[i(x)]\gets C[i(x)]+s(x) \Delta$.
		\EndProcedure
		\Procedure{Output}{}
		\State \Return $\sum_{i\in[t]} C[i]^2$.
		\EndProcedure
	\end{algorithmic}
\end{algorithm}
The standard analysis \cite{charikar04count-sketch} shows that
\begin{align}
	\E[X]   & = F_2 \label{eq:E-F2}                      \\
	\Var[X] & =2(F_2^2 - F_4)/r<2F_2^2/r \label{eq:V-F2}
\end{align}
We see that by choosing larger and larger r we can make X concentrate around $F_2=\|f\|^2_2$. Here
$X=\sum_{i\in[r]} C[i]^2=\|C\|^2_2$. Now $C$ is a randomized function
of $f$, and as $r$ grows, we get $\|C(f)\|^2_2\approx\|f\|^2_2$,
implying $\|C(f)\|_2\approx\|f\|_2$, that is, the Euclidean norm is
statistically preserved by the Count Sketch. However, the Count Sketch
is also a linear function, so Euclidean distances are statistically
preserved, that is, for any $f,g\in \Z^u$,
\[\|f-g\|_2\approx \|C(f-g)\|_2=\|C(f)-C(g)\|_2.\]
Thus, when we want to find close vectors, we can just work with the
much smaller Count Sketches.
%This is crucial to machine learning, where they adopted Count Sketches under the new name feature hashing~\cite{WDLSA09}.
The count sketch $C$ can also be used to estimate any single value $f_x$.
To do this, we use the unbiased estimator $X_x=s(x)C[i(x)]$.
This is yet another standard use of count sketch \cite{charikar04count-sketch}.
It requires direct access to both the sketch $C$ and the two hash functions $s$ and $i$.
To get concentration one takes the median of multiple such estimators.

\subsubsection{Two-for-one hash functions with b-bit hash values}
As the count sketch is described above,
it uses two independent 4-universal hash functions
$i:[u]\to[r]$ and $s:[u]\to\{-1,1\}$, but 4-universal hash functions
are generally slow to compute, so, aiming to save roughly a factor 2
in speed, a tempting idea is to compute them both using a single hash
function.

The analysis behind \eqref{eq:E-F2} and \eqref{eq:V-F2} does not quite
require $i:[u]\to[r]$ and $s:[u]\to\{-1,1\}$ to be independent.
It suffices that the hash values are uniform and that for any
given set of $j\leq 4$ distinct keys $x_0,\ldots,x_{j - 1}$, the $2j$ hash
values $i(x_0),\ldots,i(x_{j - 1}),s(x_0),\ldots,s(x_{j - 1})$ are independent.
A critical step in the analysis is that if
a value $A$ depends on the first $j-1$ values ($A=A(i(x_0),\ldots,i(x_{j - 1}),s(x_1),\ldots,s(x_{j - 1}))$), but doesn't depend
on $s(x_0)$, then
\begin{equation}\label{eq:E-0}
	\E[s(x_0) A] = 0 .
\end{equation}
This follows because $\E[s(x_0)]=0$ by uniformity of $s(x_0)$ and because $s(x_0)$ is independent of $A$.


Assuming that $r=2^\ell$ is a power of two, we can easily construct
$i:[u]\to[r]$ and $s:[u]\to\{-1,1\}$ using a single $4$-universal
hash function $h:[u]\to[2^b]$ where $b>\ell$. Recall that all the bits in
$h(x_0),\ldots,h(x_3)$ are independent. We can therefore use the
$\ell$ least significant bits of $h(x)$ for $i(x)$ and the most
significant bit of $h(x)$ for a bit $a(x)\in[2]$, and finally set
$s(x)=1-2a(x)$. It is then easy to show that if $h$ is $4$-universal
then $h$ satisfies \cref{eq:E-0}.
\begin{algorithm}[H]
	\caption{For key $x\in [u]$, compute $i(x)=i_x\in[2^\ell]$ and
	$s(x)=s_x\in\{-1,1\}$,\rule{5ex}{0ex}
	using $h:[u]\to [2^b]$ where $b>\ell$.}
	\label{alg:h-and-s}
	\begin{algorithmic}
		\State $h_x\gets h(x)$
		\Comment $h_x$ uses $b$ bits
		\State $i_x\gets h_x \andtt (2^\ell-1)$
		\Comment $i_x$ gets $\ell$ least significant bits of $h_x$
		\State $a_x\gets h_x\rs (b-1)$
		\Comment $a_x$ gets the most significant bit of $h_x$
		\State $s_x\gets 1-(a_x\ls1)$
		\Comment $a_x\in[2]$ is converted to a sign $s_x\in\{-1,1\}$
	\end{algorithmic}
\end{algorithm}
% \begin{lemma}\label{lem:b-bit-hashing} Suppose $h:[u]\to[2^b]$ is $k$-universal. Let
%    $i:[u]\to[2^\ell]$ and
%    $s:[u]\to\{-1,1\}$ be constructed from $h$ as described in Algorithm \ref{alg:h-and-s}. Then $h$ and $s$ are both $k$-universal. Moreover, for
%    any $j\leq k$ distinct keys $x_1,\ldots,x_j$, the $2j$ hash
%    values $i(x_1),\ldots,i(x_j),s(x_1),\ldots,s(x_j)$ are universal.
%    In particular, if $A$ depends on
%    $i(x_1),\ldots,i(x_j),s(x_2),\ldots,s(x_j)$, but not on $s(x_1)$, then
%    \begin{equation}\label{eq:E-0}
%       \E[s(x_1)A]=0
%    \end{equation}
% \end{lemma}
Note that Algorithm \ref{alg:h-and-s} is well defined as long as
$h$ returns a $b$-bit integer. However, \cref{eq:E-0} requires
that $h$ is $k$-universal into $[2^b]$, which in particular implies that
the hash values are uniform in $[2^b]$.


\subsubsection{Two-for-one hashing with  Mersenne primes}\label{sec:two-for-one}
Above we discussed how useful it would be with $k$-universal hashing
mapping uniformly into $b$-bit strings. The issue was that the lack of
efficient implementations with standard portable code if
$k>2$. However, when $2^b-1$ is a Mersenne prime $p\geq u$, then we do
have the efficient computation from Algorithm \ref{alg:Mersenne}
of a $k$-universal hash function $h:[u]\to[2^b-1]$. The hash values
are $b$-bit integers, and they are uniformly distributed, except that
we are missing the all \texttt{1}s value $p=2^b-1$. We want to
understand how this missing value affects us if we try to split the
hash values as in Algorithm \ref{alg:h-and-s}. Thus, we assume a
$k$-universal hash function $h:[u]\to[2^b-1]$ from which we construct
$i:[u]\to[2^\ell]$ and $s:[u]\to\{-1,1\}$ as
described in Algorithm \ref{alg:h-and-s}. As usual, we assume $2^\ell>1$.
Since $i_x$ and $s_x$ are
both obtained by selection of bits from $h_x$, we know from Section
\ref{sec:power-of-two} that each of them have close to uniform
distributions. However, we need a good replacement for \eqref{eq:E-0}
which besides uniformity, requires $i_x$ and $s_x$ to be independent,
and this is certainly not the case.

Before getting into the analysis, we argue that we really do get two
hash functions for the price of one. The point is that our efficient
computation in Algorithm \ref{alg:Mersenne} requires that we use a
Mersenne prime $2^b-1$ such that $u\leq 2^{b-1}$, and this is even if
our final target is to produce just a single bit for the sign function
$s:[u]\to\{-1,1\}$. We also know that $2^\ell<u$, for otherwise we
get perfect results implementing $i:[u]\to[2^\ell]$ as the identity
function (perfect because it is collision-free).  Thus we can assume
$\ell<b$, hence that $h$ provides enough bits for both $s$ and $i$.


We now consider the effect of the hash values from $h$ being uniform
in $[2^b-1]$ instead of in $[2^b]$. Suppose we want to compute the
expected value of an expression $B$ depending only on the independent
hash values $h(x_0),\ldots,h(x_{j - 1})$ of $j\leq k$ distinct keys
$x_0,\ldots,x_{j - 1}$.

Our generic idea is to play with the distribution of $h(x_0)$ while
leaving the distributions of the other independent hash values
$h(x_0)\ldots,h(x_{j - 1})$ unchanged, that is, they remain uniform in
$[2^b-1]$. We will consider having $h(x_0)$ uniformly distributed in
$[2^b]$, denoted $h(x_0) \sim \unif[2^b]$, but then we later have to
subtract the ``fake'' case where $h(x_0)=p=2^b-1$.  Making the
distribution of $h(x_0)$ explicit, we get
\begin{equation}\begin{split}
		\E_{h(x_0) \sim \unif[p]}[B]&=\sum_{y\in[p]}\E[B \mid h(x_0)=y]/p
		\\&=\sum_{y\in[2^b]}\E[B \mid h(x_0)=y]/p - \E[B \mid h(x_0)=p]/p
		\\ &=\E_{h(x_0) \sim \unif[2^b]}[B](p+1)/p - \E[B \mid h(x_0)=p]/p.\label{eq:play-with-dist}
	\end{split}\end{equation}
Let us now apply this idea our situation where $i:[u]\to[2^\ell]$ and
$s:[u]\to\{-1,1\}$ are constructed from $h$ as described in Algorithm
\ref{alg:h-and-s}. We will prove
\begin{lemma}\label{lem:remove-si}  Consider distinct keys $x_0,\ldots,x_{j - 1}$, $j\leq k$ and an expression $B=s(x_0)A$ where $A$
	depends on $i(x_0),\ldots,i(x_{j - 1})$ and $s(x_1),\ldots,s(x_{j - 1})$ but not
	$s(x_0)$. Then
	\begin{equation}\label{eq:remove-si}
		\E[s(x_0)A]=\E[A\mid i(x_0)=2^\ell-1]/p.
	\end{equation}
\end{lemma}
\begin{proof}
	When $h(x_0) \sim \unif[2^b]$, then $s(x_0)$ is uniform
	in $\{-1,1\}$ and independent of $i(x_0)$. The remaining
	$(i(x_i),s(x_i))$, $i\ge 1$, are independent of $s(x_0)$ because they
	are functions of $h(x_i)$ which is independent of $h(x_0)$, so
	we conclude that
	\[\E_{h(x) \sim \unif[2^b]}[s(x_0)A]=0\]
	Finally, when $h(x_0)=p$, we get $s(x_0)=-1$ and $i(x_0)=2^\ell-1$,
	so applying \eqref{eq:play-with-dist}, we conclude
	that
	\[\E[s(x_0)A] = -\E[s(x_0) A \mid h(x_0) = p]/p = \E[A \mid i(x_0)=2^\ell-1]/p.\]
\end{proof}
Above \eqref{eq:remove-si} is our replacement for \eqref{eq:E-0}, that is,
when the hash values from $h$ are uniform in $[2^b-1]$ instead of
in $[2^b]$, then $\E[s(x_0)B]$ is reduced by $\E[B \mid i(x_0)=2^\ell-1]/p$.
For large $p$, this is a small additive error. Using this in a careful
analysis, we will show that our fast second moment estimation
based on Mersenne primes performs almost perfectly:

\begin{theorem}\label{thm:h-and-s-p}
	Let $r>1$ and $u>r$ be powers of two and let $p=2^b-1>u$ be a
	Mersenne prime.
	Suppose we have a 4-universal hash function $h:[u]\to[2^b-1]$, e.g.,
	generated using Algorithm \ref{alg:Mersenne}. Suppose
	$i:[u]\to[r]$ and
	$s:[u]\to\{-1,1\}$ are constructed from $h$ as described in
	Algorithm \ref{alg:h-and-s}. Using this $i$ and $s$
	in the Count Sketch Algorithm \ref{alg:count-sketch}, the second moment
	estimate $X=\sum_{i\in[k]} C_i^2$ satisfies:
	\begin{align*}
		\E[X] < (1+n/p^2)\,F_2,
		\quad
		|\E[X] - F_2 | \le F_2 (n - 1)/p^2,
		\quad
		\Var[X]< 2F_2^2/r.
	\end{align*}
\end{theorem}
The difference from \eqref{eq:E-F2} and \eqref{eq:V-F2}
is negligible when $p$ is large. Theorem \ref{thm:h-and-s-p} will be
proved in Section \ref{sec:analysis-two-for-one}.

Recall our discussion from the end of Section
\ref{sec:power-of-two}. If we instead had used the $b$-bit prime
$p=2^{b-1}+1$, then the sign-bit $a_x$ would be extremely biased with
$\Pr[a_x=0]=1-1/p$ while $\Pr[a_x=1]=1/p$, leading to extremely poor
performance.


\subsection{An arbitrary number of buckets}\label{sec:most-uniform}
We now consider the general case where we want to hash into a set of
buckets $R$ whose size is not a power of two.  Suppose we have a
$2$-universal hash function $h:U\to Q$.  We will compose $h$ with a
map $\mu:Q\to R$, and use $\mu\circ h$ as a hash function from $U$ to
$R$.  Let $q=|Q|$ and $r=|R|$.  We want the map $\mu$ to be \emph{most
	uniform} in the sense that for bucket $i\in R$, the number of
elements from $Q$ mapping to $i$ is either $\floor{q/r}$ or
$\ceil{q/r}$.  Then the uniformity of hash values with $h$ implies for
any key $x$ and bucket $i\in R$ \[\floor{q/r}/q\leq
	\Pr[\mu(h(x))=i]\leq \ceil{q/r}/q.\] Below we typically have $Q=[q]$
and $R=[r]$.  A standard example of a most uniform map $\mu:[q]\to[r]$
is $\mu(x)=x\bmod r$ which the one used above when we defined
$h^r:[u]\to[r]$, but as we mentioned before, the modulo operation is
quite slow unless $r$ is a power of two.

Another example of a most uniform map $\mu:[q]\to[r]$
is $\mu(x)=\floor{xr/q}$,
which is also quite slow in general, but if $q=2^b$ is a power of two,
it can be implemented as $\mu(x)=(xr)\rs\,b$ where
$\rs$ denotes right-shift. This would be yet another advantage
of having $k$-universal hashing into $[2^b]$.

Now, our interest is the case where $q$ is a Mersenne prime $p=2^b-1$. We want
an efficient and most uniform map $\mu:[2^b-1]$ into any given $[r]$.
Our simple solution is to define
\begin{equation}\label{eq:most-uniform}
	\mu(v)=\floor{(v+1)r/2^b}=((v+1)r)\rs b.
\end{equation}
Lemma \ref{lem:most-uniform} (iii) below
states that \eqref{eq:most-uniform} indeed
gives a most uniform map.
\begin{lemma}\label{lem:most-uniform} Let $r$ and $b$ be positive integers.
	%, and let $v\in [2^b-1]$.
	Then
	\begin{itemize}
		\item[(i)] $v\mapsto (vr)\rs\,b$ is a most
		      uniform map from $[2^b]$ to $[r]$.
		\item[(ii)] $v\mapsto (vr)\rs\,b$ is a most
		      uniform map from $[2^b]\setminus\{0\}=\{1,\ldots,2^b-1\}$ to $[r]$.
		\item[(iii)] $v\mapsto ((v+1)r)\rs \, b$ is a most
		      uniform map from $[2^b-1]$ to $[r]$.
	\end{itemize}
\end{lemma}
\begin{proof}
	Trivially (ii) implies (iii).
	The statement (i) is folklore and easy to prove, so we know that every
	$i\in[r]$ gets hit by $\floor {2^b/r}$ or $\ceil{2^b/r}$ elements from
	$[2^b]$. It is also clear that $\ceil{2^b/r}$ elements, including $0$,
	map to $0$. To prove (ii), we remove $0$ from $[2^b]$,
	implying that only
	$\ceil{2^b/r}-1$ elements map to $0$. For all positive integers $q$
	and $r$, $\ceil{(q+1)/r}-1=\floor{q/r}$, and we use this here with
	$q=2^b-1$. It follows that all buckets from $[r]$ get $\floor{q/r}$
	or $\floor{q/r}+1$ elements from $Q=\{1,\ldots,q\}$. If $r$ does
	not divide $q$ then $\floor{q/r}+1=\ceil{q/r}$, as desired. However,
	if $r$ divides $q$, then $\floor{q/r}=q/r$, and this
	is the least number of elements from $Q$ hitting any bucket in $[r]$. Then
	no bucket from $[r]$ can get hit by more than $q/r=\ceil{q/r}$
	elements from $Q$. This completes the proof of (ii), and hence of (iii).
\end{proof}
We note that our trick does not work when $q=2^b-c$ for $c\geq 2$, that is,
using $v\mapsto ((v+c)r)\rs  b$, for in this general case,
the number of elements hashing to $0$ is $\ceil {2^b/r}-c$, or $0$ if
$c\geq \floor {2^b/r}$.
One may try many other hash functions $(c_1 v r+ c_2 v+ c_3 r + c_4) \rs b$ similarly without any luck.
Our new uniform map from \eqref{eq:most-uniform} is thus very specific to Mersenne prime fields.

% TODO: Hvad er det her?
%For general $c\ge 2$ we provide a scheme using two shifts in
%Section \ref{sec:pseudo-arbitrary}.




\subsection{Division and Modulo with (Pseudo) Mersenne Primes}\label{subsec:intro-division}

We now describe a new algorithm for truncated division with Mersenne primes, and more generalized numbers on the form $2^b-c$.
We show this implies a fast branch-free computation of $\bmod\,p$ for
Mersenne primes $p=2^b-1$.
An annoyance in Algorithm \ref{alg:Mersenne}
is that the if-statement at the end can be slow in case of branch mis-predictions.
This method solves that issue.

More specifically, in Algorithm \ref{alg:Mersenne}, after the last
multiplication, we have a number $y<p^2$ and we want to compute the
final hash value $y\bmod p$. We obtained this using the following
statements, each of which preserves the value modulo $p$, starting from
$y<p^2$:
\begin{algorithmic}
	\State $y \gets (y\andtt p)+(y\rs b)$
	\Comment $y<2p$
	\If{$y\ge p$}
	\State $y\gets y-p$
	\Comment  $y<p$
	\EndIf
\end{algorithmic}
To avoid the if-statement, in Algorithm \ref{alg:div-simple}, we suggest
a branch-free code that starting
from $v<2^{2b}$ computes both $y=v\bmod p$ and $z=\floor{v/p}$ using
a small number of AC$^0$ instructions.
\begin{algorithm}[H]
	\caption{For Mersenne prime $p=2^b-1$ and $v< 2^{2b}$, compute
		\label{alg:div-simple}
		$y=v\bmod p$ and $z=\floor{v/p}$}
	\begin{algorithmic}
		\State $\rhd$ First we compute $z=\floor{v/p}$
		\State $v'=v+1$
		\State $z \gets(( v' \rs b)+v')\rs b$
		%\State $y \gets v - (z \ls b) + z$.
		\State $\rhd$ Next we compute $y=v\bmod p$ given $z=\floor{v/p}$
		\State $y \gets (v + z) \andtt p $
	\end{algorithmic}
\end{algorithm}
In Algorithm \ref{alg:div-simple}, we use
$z=\floor{v/p}$ to compute $y=v\bmod p$. If we only want the
division $z=\floor{v/p}$, then we can skip the last statement.

Below we will generalize Algorithm \ref{alg:div-simple} to work for
arbitrary $v$, not only $v<2^{2b}$. Moreover, we will generalize
to work for different kinds of primes generalizing Mersenne primes:
\begin{description}
	\item[Pseudo-Mersenne Primes]
	      are primes of the form $2^b-c$, where is usually required that $c < 2^{\lfloor b/2\rfloor}$~\cite{van2014encyclopedia}.
	      Crandal patented a method for working with Pseudo-Mersenne Primes in 1992~\cite{crandall1992method},
	      why those primes are also sometimes called ``Crandal-primes''.
	      The method was formalized and extended by Jaewook Chung and Anwar Hasan in 2003~\cite{chung2003more}. The method we present is simpler with
	      stronger guarantees and better practical performance.
	      We provide a comparison with the Crandal-Chung-Hansan method in Section 4.
	\item[Generalized Mersenne Primes]
	      also sometimes known as Solinas primes~\cite{Solinas2011}, are sparse numbers, that is $f(2^b)$ where $f(x)$ is a low-degree polynomial.
	      Examples from the Internet Research Task Force's document ``Elliptic Curves for Security''~\cite{rfc7748}:
	      $p_{25519} = 2^{255} - 19$
	      and
	      $p_{448} = 2^{448}-2^{224}-1$.
	      We simply note that Solinas primes form a special case of
	      Pseudo-Mersenne Primes, where multiplication with $c$
	      can be done using a few shifts and additions.
\end{description}
We will now first generalize the division from Algorithm \ref{alg:div-simple} to cover arbitrary $v$ and division with an arbitrary Pseudo-Mersenne primes $p=2^b-c$.
This is done in Algorithm \ref{alg:division-generalized} below which
works also if $p=2^b-c$ is not a prime.  The
simple division in Algorithm \ref{alg:div-simple} corresponds to the case
where $c=1$ and $m=2$.
\begin{algorithm}[H]
	\caption{Given integers $p=2^b-c$ and $m$.
		For any $v< (2^b/c)^m$, compute $z=\floor{v/p}$}
	\label{alg:division-generalized}
	\begin{algorithmic}
		%\Procedure{Divide}{v, n, c}
		\State $v' \gets v + c$
		\State $z \gets v' \rs b$
		%\For{$i\gets 1$ \textbf{to} $m$}
		\For{ $m-1$ times}
		\State $z \gets (z * c + v')\rs b$
		\EndFor
		%\EndFor
		%\State \Return $v$
		%\EndProcedure
	\end{algorithmic}
\end{algorithm}
The proof that Algorithm \ref{alg:division-generalized} correctly computes
$z=\floor{v/p}$ is provided in Section \ref{sec:division}.
Note that $m$ can be computed in advance from $p$, and there is no requirement that it is chosen as small as possible.
For Mersenne and Solinas primes, the multiplication $z*c$ can be done very fast.

Mathematically the algorithm computes the nested division
$$
	\bbfloor{\frac{v}{q-c}}
	=
	\bbfloor{\frac{
			\bfloor{\frac{
					\floor{\frac{
							\dots+v+c
						}{q}}c +v+c
				}{q}}c +v+c
		}{q}}
	\vspace{-1em} % Move the next line further up
$$
which is visually similar to the series expansion
$
	\frac{v}{q-c}
	= \frac{v}{q}\sum_{i=0}^\infty (\frac{c}{q})^i
	%= v\frac{1+\frac{c+\frac{c^2 + \dots}{q}}{q}}{q}
	= \frac{\frac{\frac{\dots+v}{q}c+v}{q}c+v}{q}.
$
It is natural to truncate this after $m$ steps for a $(c/q)^m$ approximation.
The less intuitive part is that we need to add $v+c$ rather than $v$ at each step, to compensate for rounding down the intermediate divisions.

\paragraph{Computing mod}
We will now compute the $\bmod$ operation assuming that
we have already computed $z=\floor{v/p}$. Then
\begin{align}
	v \bmod p
	= v - pz
	= v - (2^b-c)z
	= v - (z\ls b) - c*z,
\end{align}
which is only two additions, a shift, and a multiplication with $c$ on top of the division algorithm.
As $pz = \floor{v/p}p \le v$ there is no danger of overflow.
We can save one operation by noting
that if $v = z (2^b-c) + y$, then
$$v\bmod p = y=\left(v+c*z \right) \bmod 2^b.$$
This is the method presented in Algorithm \ref{alg:mod-generalized} and applied with $c=1$ in Algorithm \ref{alg:div-simple}.
\begin{algorithm}[H]
	\caption{For integers $p=2^b-c$ and $z=\floor{v/p}$ compute
		$y=v \bmod p$.}
	\label{alg:mod-generalized}
	\begin{algorithmic}
		\State $y \gets (v + z*c) \andtt (2^b-1)$
	\end{algorithmic}
\end{algorithm}



%In the case $x\le 2^{2b}$ and $c=1$, we get the simplified Algorithm \ref{alg:div-simple} described above: $ \left\lfloor\frac{x}{2^n-1}\right\rfloor = (x+1 \rs n)+x+1 \rs n$.

% TODO: These applications need to be written properly.
% \subsubsection{Applications}\label{sec:general-applications}
% 
% \paragraph{To an arbitrary number of buckets}
% In Subsection~\ref{sec:most-uniform} we discussed how $\floor{\frac{h(x)r}{2^b-1}}$ provides a most uniform map from $[2^b-1]\to[r]$.
% To avoid the division step, we instead considered the map
% $\floor{\frac{(h(x)+1)r}{2^b}}$.
% However, for primes of the form $2^b-c$, $c>1$ this approach doesn't provide a most-uniform map.
% %
% Instead, we may use Algorithm \ref{alg:division-generalized} to compute
% $$\left\lfloor\frac{h(x)r}{2^b-c}\right\rfloor$$
% directly, getting a perfect most-uniform map.
% %(Another alternative was to pre-compute $q = \lfloor2^b/p\rfloor$ and take
% %$\floor{\frac{h(x)rq}{2^b}}$, however that requires larger words to store the product $h(x)rq$.)
% 
% \paragraph{Application to Finger Printing}
% A classical idea by Rabin~\cite{rabin1981fingerprinting} is to use test the equality of two large numbers by comparing their value modulo a random prime.
% A beautiful example of this is King and Sagert's Algorithm for Maintaining the Transitive Closure.~\cite{DBLP:journals/jcss/KingS02}
% These cases are typically non-trivial to convert to random fields other than $\Z_p$, and we need a reasonably large set of random primes to choose from.
% The generalized Mersenne primes with $c$ of the other $2^{b(1-\eps)}$ are a good candidate, since the range ...
% Using an idea like \eqref{eq:Mersenne} we can note
% \begin{equation}
% 	y \equiv y - \floor{y/2^b}(2^b-c)
% 	= (y\bmod 2^{b}) + c\floor{y/2^b}
% 	\pmod {2^b-c}.
% \end{equation}
% Each application reduces $y$ by a factor $\approx 2^{-\eps b}$.
% So if we multiply two numbers



% On the number of Mersenne Primes:
%Unfortunately there are only 45 of them known.
%The most useful one perhaps being.
%Heuristically there are $O(\log x)$ Mersenne primes up to $x$.
%Trivia: Euler proved that an even number $n$ is perfect if and only if it is of the form $n=2^{q-1}M_q$, where $M_q=2^q-1$ is prime.
%(Usually we know a number is perfect if its divisors sum to the number itself, e.g. $6=1+2+3$ or $28=1+2+4+7+14$.)


%[[Curve448]] uses the Solinas prime <math>2^{448} - 2^{224} - 1</math>
