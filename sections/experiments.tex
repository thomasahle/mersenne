%! TEX root = ../mersenne.tex
\section{Experiments}\label{sec:experiments}
We perform experiments on fast implementations of Mersenne hashing (\Cref{alg:Mersenne}) and our Mersenne division algorithm (\Cref{alg:division-generalized}).
All code is available in our repository\\\href{https://github.com/thomasahle/mersenne/}{github.com/thomasahle/mersenne} and compiled with \texttt{gcc -O3}.

We tested \Cref{alg:Mersenne} against hashing over the finite field $GF(2^{64})$.
The later is implemented, following Lemire~\cite{lemire2014strongly}, using the ``Carry-less multiplication' instruction, CLMUL, supported by AMD and Intel processors~\cite{GUERON2010549}.\footnote{
More precisely, given two $b$-bit numbers $\alpha = \sum_{i = 0}^{b - 1} \alpha_i 2^i$ and $\beta = \sum_{i = 0}^{b - 1} \beta_i 2^i$
the CLMUL instructions calculates $\gamma = \sum_{i = 0}^{2b - 2} \gamma_i 2^i$, where $\gamma_i = \bigoplus_{j = 0}^{j} \alpha_i \beta_{j - i}$.
If we view $\alpha$ and $\beta$ as elements in $GF(2)[x]$ then the CLMUL instruction corresponds to polynomial multiplication.
We can then calculate multiplication in a finite field, $GF(2^b)$, efficiently by noting that for any irreducible polynomial $p(x) \in GF(2)[x]$
of degree $b$ then $GF(2^b)$ is isomorphic to $GF(2)[x] / p(x)$. If we choose $p(x)$ such that the degree of $p(x) - 2^{b}$ is at
most $b/2$ then modulus $p(x)$ can be calculated using two CLMUL instructions.
For $GF(2^{64})$ we use the polynomial $p(x) = x^{64} + x^4 + x^3 + x + 1$.
}
%
We hash a large number of $64$-bit keys into $[p]$ for $p=2^{89}-1$ using $k$-universal hashing for $k \in \{2, 4, 8\}$.
%Note that we need $p\ge 2^{64}$ to support any range 
Since the intermediate values of our calculations take up to $64 + 89$ bits, all computations of \Cref{alg:Mersenne} are done with 128-bit output registers.
%We use the Mersenne prime $p = 2^{89} - 1$ and we have to implement multiplication between
%$89$-bit and $64$-bit numbers. This is implemented by two multiplications between to $64$-bit
%numbers with $128$-bit output.

\begin{table}[H]
   \centering
   \begin{tabular}{c c}
      \begin{tabular}{r | r r}
         $k$ & \Cref{alg:Mersenne}       & $GF(2^{64})$-Hashing \\
         \hline
         2 & 23.6 & \textbf{15.1} \\
         4 & \textbf{65.7} & \textbf{65.7} \\
         8 & \textbf{178.4} & 242.4 \\
      \end{tabular}
      \hspace{.5em}
      &
      \hspace{.5em}
      \begin{tabular}{r | r r}
         $k$ & \Cref{alg:Mersenne}       & $GF(2^{64})$-Hashing \\
         \hline
         $2$ & 19.0           & \textbf{16.7} \\
         $4$ & \textbf{68.7}  & 68.8 \\
         $8$ & \textbf{187.4} & 246.8
      \end{tabular}
   \end{tabular}
   \caption{Milliseconds for $10^7$ $k$-universal hashing operations on 64bit keys with $p=2^{89}-1$.
      The standard deviation is less than $\pm1$ms.
         On the left, Intel Core i7-8850H.
         On the right, Intel Core i7-86650U.
   }
   \label{tab:hashing-experiments}
\end{table}

\begin{table}[H]
   \centering
   \begin{tabular}{c c}
      \begin{tabular}{r | r r}
         $k$ & \Cref{alg:Mersenne}       & $GF(2^{64})$-Hashing \\
         \hline
         2& 13.6 & \textbf{13.0} \\
         4& \textbf{31.6} & 60.3 \\
         8&\textbf{88.0} & 218.7
      \end{tabular}
      \hspace{.5em}
      &
      \hspace{.5em}
      \begin{tabular}{r | r r}
         $k$ & \Cref{alg:Mersenne}       & $GF(2^{64})$-Hashing \\
         \hline
         $2$ & 19.0           & \textbf{16.7} \\
         $4$ & \textbf{68.7}  & 68.8 \\
         $8$ & \textbf{187.4} & 246.8
      \end{tabular}
   \end{tabular}
   \caption{Milliseconds for $10^7$ $k$-universal hashing operations on 64bit keys with $p=2^{61}-1$.
      The standard deviation is less than $\pm1$ms.
         On the left, Intel Core i7-8850H.
         On the right, Intel Core i7-86650U.
   }
   \label{tab:hashing-experiments2}
\end{table}

The results in \Cref{tab:hashing-experiments} show that our methods outperform carry-less Multiplication for larger $k$, while being slower for $k=2$.
We note though that the multiply-shift scheme~\cite{dietzfel96universal} is better yet in that regime.
For $k=4$, which we use for Count Sketch, the results are a tossup.
However, we note that our methods are more portable than carry-less, and we keep the two-for-one advantages described in the article.
For $k = 8$, using a Mersenne prime is significantly faster.
\vspace{.5em} % Soft section break

We tested \Cref{alg:division-generalized} against the state of the art modified Crandall's algorithm by Chung and Hasan (\Cref{alg:cch}), as well as the built in truncated division algorithm in the GNU MultiPrecision Library, GMP~\cite{granlund2010gnu}.

\begin{table}[H]
   \centering
   \begin{tabular}{ c c }
      \begin{tabular}{ r | r r r }
         $b$ & Crandall & \Cref{alg:division-generalized} & GMP \\
         \hline
         32 & 396 & \textbf   {138}  & 149\\
         64 & 381 &   \textbf {142}  & 161\\
         128 & 564 &  \textbf {157}  & 239\\
         256 & 433 &  \textbf {187}  & 632\\
         512 & 687 &  \textbf {291}  & 1215\\
         1024 & 885 & \textbf {358}  & 2802
      \end{tabular}
      \hspace{.5em}
      &
      \hspace{.5em}
      \begin{tabular}{ r | r r r }
         $b$ & Crandall & \Cref{alg:division-generalized} & GMP \\
         \hline
         32 & 438 & 172 & \textbf{125}\\
         64 & 422 & 172 & \textbf{141}\\
         128 & 578 &      \textbf{188} & 235\\
         256 & 454 &      \textbf{219} & 469\\
         512 & 703 &      \textbf{297} & 938\\
         1024 & 875 &     \textbf{391} & 2172
      \end{tabular}
   \end{tabular}
   \caption{Milliseconds for $10^7$ divisions of $2b$-bit numbers with $p=2^b-1$.
      The standard deviation is less than $\pm10$ms.
         On the left, Intel Core i7-8850H.
         On the right, Intel Core i7-86650U.
   }
   \label{tab:division-experiments}
\end{table}

The results in \Cref{tab:division-experiments} show that our method always outperforms the modified Crandall's algorithm, which itself outperforms GMP's division at larger bit-lengths.
At shorter bit-lengths it is mostly a toss-up between our method and GMP's.

We note that our code for this experiment is implemented entirely in GMP, which includes some overhead that could perhaps be avoided in an implementation closer to the metal.
This overhead is very visible when comparing \Cref{tab:hashing-experiments} and \Cref{tab:division-experiments}, suggesting that an optimized \Cref{alg:division-generalized} would beat GMP even at short bit-lengths.

