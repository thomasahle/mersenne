
%! TEX root = ../mersenne.tex
\section{Algorithms and analysis with arbitrary number of buckets}\label{sec:arbitrary-buckets}
We now consider the case where we want to hash into
a number of buckets. We will analyse the collision probability
with most uniform maps introduced in Section \ref{sec:most-uniform},
and later we will show how it can be used in connection with the
two-for-one hashing from Section \ref{sec:two-for-one}.

\subsection{Two-for-one hashing from uniform bits to arbitrary number of buckets}
We have a hash function $h:U\to Q$, but we want hash values in $R$, so
we need a map $\mu:Q\to R$, and then use $\mu\circ h$ as
our hash function from $U$ to $R$. We normally assume that the hash values 
with $h$ are pairwise independent, that is, for any distinct $x$ and $y$,
the hash values $h(x)$ and $h(y)$ are independent, but then 
$\mu(h(x))$ and $\mu(h(y))$ are also independent. This means
that the collision probability can be calculated
as 
\[\Pr[\mu(h(x))=\mu(h(y))]=\sum_{i\in R}\Pr[\mu(h(x))=\mu(h(y))=i]=\sum_{i\in R}\Pr[\mu(h(x)=i)]^2.\]
This sum of squared probabilities attains is minimum value $1/|R|$
exactly when $\mu(h(x))$ is uniform in $R$. 

Let $q=|Q|$ and $r=|R|$. Suppose that $h$ is $2$-universal. Then
$h(x)$ is uniform in $Q$, and then we get the lowest collision
probability with $\mu\circ h$ if $\mu$ is most uniform as defined in
Section \ref{sec:most-uniform}, that is, the number of elements from
$Q$ mapping to any $i\in[r]$ is either $\floor{q/r}$ or
$\ceil{q/r}$. To calculate the collision probability,
Let $a\in[r]$ be such that $r$ divides $q+a$. Then the map $\mu$ maps
$\ceil{q/r}=(q+a)/r$ balls to $r-a$ buckets and
$\floor{q/r}=(q+a-r)/r$ balls to $a$ buckets. For a key $x\in [u]$, we
thus have $r-a$ buckets hit with probability $(1+a/q)/r$ and
$a$ buckets hit with probability $(1-(r-a)/q)/r$.
The collision probability is then
\begin{equation}\begin{split}
   \Pr[\mu(h(x))=\mu(h(y))]
                  &= (r-a)((1+a/q)/r)^2+a((1-(r-a)r/q)/r)^2
%                 \\&=\frac{(r-a)+(r-a)2a/q+(r-a)a^2/q^2+ a-a^2(r-a)/p+a(r-a)^2/q^2}{r^2}
%                 \\&=\frac{r +r a (r-a)/q^2}{r^2}
                 \\&=(1+a(r-a)/q^2)/r
                 \\&\le \left(1+(r/(2q))^2\right)/r.\label{eq:coll-a}
\end{split}\end{equation}
Note that the above calculation generalizes the one for \eqref{eq:coll} which
had $a=1$. We will think of $(r/(2q))^2$ as the general relative rounding
cost when we do not have any information about how $r$ divides $q$.

\subsection{Two-for-one hashing from uniform bits to arbitrary number of buckets}
We will now briefly discuss how would get the two-for-one hash
functions in count sketches with an arbitrary number $r$ of buckets based
on a single $4$-universal hash function $h:[u]\to [2^b]$.  We want to
construct the two hash functions $s:[u]\to\{-1,1\}$ and
$i:[u]\to[r]$. As usual the results with uniform $b$-bit strings will
set the bar that we later compare with when from $h$ we get hash values that
are only uniform in $[2^b-1]$.

The construction of $s$ and $i$ is presented in 
Algorithm \ref{alg:b-bit-arb-r}.
\begin{algorithm}[H]
   \caption{For key $x\in [u]$, compute $i(x)=i_x\in[r]$ and $s(x)=s_x\in\{-1,1\}$.
   \newline
    Uses 4-universal $h:[u]\to [2^b]$.}
   \label{alg:b-bit-arb-r}
   \begin{algorithmic}
      \State $h_x\gets h(x)$
      \Comment $h_x$ has $b$ uniform bits
      \State $j_x\gets h_x\andtt(2^{b-1}-1)$
      \Comment $j_x$ gets $b-1$ least significant bits of $h_x$
      \State $i_x\gets (r*j_x)\rs (b-1)$
      \Comment $i_x$ is most uniform in $[r]$
      \State $a_x\gets h_x\rs (b-1)$
      \Comment $a_x$ gets the most significant bit of $h_x$
      \State $s_x\gets (a_x\ls 1)-1$
      \Comment $s_x$ is uniform in $\{-1,1\}$ and independent of $i_x$.
   \end{algorithmic}
\end{algorithm}
The difference relative to Algorithm \ref{alg:h-and-s} is the computation
of $i_x$ where we now first pick out the $(b-1)$-bit string $j_x$ from
$h_x$, and then apply the most uniform map $(rj_x)\rs (b-1)$
to get $i_x$. This does not affect $s_x$ which remains independent
of $i_x$, hence we still have \nameref{prop:independence}.
But $i_x$ is no longer uniform in $[r]$ and only most uniform
so by \eqref{eq:coll-a} we have $(1 + (r/2^b)^2)/r$-low collision probability.
Now \Cref{lem:count-classic} give us $\E[X] = F_2$ and
\begin{equation}\label{eq:Var-b-bit-arb-r}
   \Var[X] \le 2(F_2^2 - F_4)\left(1+(r/2^b)^2\right)/r
      \le 2 F_2^2\left(1 + (r/2^b)^2 \right)/r .
\end{equation}

\subsection{Two-for-one hashing from Mersenne primes to arbitrary number of buckets}
We will now show how wan get the two-for-one hash functions in count
sketches with an arbitrary number $r$ of buckets based on a single
$4$-universal hash function $h:[u]\to [2^b-1]$.  Again we want to
construct the two hash functions $s:[u]\to\{-1,1\}$ and
$i:[u]\to[r]$.  The construction will be the same as we had in
Algorithm \ref{alg:b-bit-arb-r} when $h$ returned uniform values in
$[2^b]$ with the change that we set $h_x\gets h(x)+1$, so that it
becomes uniform in $[2^b]\setminus\{0\}$. It is also convenient to
swap the sign of the sign-bit $s_x$ setting $s_x\gets 2a_x - 1$ instead
of $s_x\gets 1-2a_x$. The basic reason is that this makes the analysis
cleaner. The resulting algorithm
is presented as Algorithm \ref{alg:Mersenne-arb-r}.
\begin{algorithm}[H]
   \caption{For key $x\in [u]$, compute $i(x)=i_x\in[r]$ and
      $s(x)=s_x\in\{-1,1\}$.\rule{5ex}{0ex}
   Uses 4-universal $h:[u]\to [p]$ for Mersenne prime $p=2^b-1\geq u$.}
   \label{alg:Mersenne-arb-r}
   \begin{algorithmic}
      \State $h_x\gets h(x)+1$
      \Comment $h_x$ uses $b$ bits uniformly except $h_x\neq 0$
      \State $j_x\gets h_x\andtt(2^{b-1}-1)$
      \Comment $j_x$ gets $b-1$ least significant bits of $h_x$
      \State $i_x\gets (r*j_x)\rs (b-1)$
      \Comment $i_x$ is quite uniform in $[r]$
      \State $a_x\gets h_x\rs (b-1)$
      \Comment $a_x$ gets the most significant bit of $h_x$
      \State $s_x\gets 1-(a_x\ls1)$
      \Comment $s_x$ is quite uniform in $\{-1,1\}$ and quite independent of $i_x$.
   \end{algorithmic}
\end{algorithm}
The rest of Algorithm \ref{alg:Mersenne-arb-r} is exactly like 
Algorithm \ref{alg:b-bit-arb-r}, and we will now discuss the new
distributions of the resulting variables. We had
$h_x$ uniform in $[2^b]\setminus\{0\}$, and then we set
$j_x \gets h_x\andtt(2^{b-1}-1)$. Then $j_x\in[2^{b-1}]$ with 
$\Pr[j_x=0]=1/(2^{b}-1)$ while  $\Pr[j_x=j]=2/(2^{b}-1)$ for all $j>0$.

Next we set $i_x\gets (rj_x)\rs b-1$. We know from Lemma
\ref{lem:most-uniform} (i) that this is a most uniform map from
$[2^{b-1}]$ to $[r]$.  It maps a maximal number of elements from
$[2^{b-1}]$ to $0$, including $0$ which had half probability for
$j_x$.
We conclude
\begin{align}
   \Pr[i_x=0] &= (\ceil{2^{b-1}/r}2-1)/(2^{b}-1)
   \label{eq:prix0}
   \\
   \Pr[i_x = i] &\in
   \{\floor{2^{b-1}/r}2/(2^{b}-1), \ceil{2^{b-1}/r}2/(2^{b}-1)\}
   \mbox{ for $i \neq  0$}
   \label{eq:prixneq0}
   .
\end{align}
%all $i\in[r]\setminus\{0\}$ have probability
%while
%$0$ has probability $(\ceil{2^{b-1}/r}2-1)/(2^{b}-1)$. 
We note
that the probability for $0$ is in the middle of the two other
bounds and often this yields a more uniform distribution on $[r]$ than
the most uniform distribution we could get from the
uniform distribution on $[2^{b-1}]$.

With
more careful calculations, we can get some nicer bounds
that we shall later use.
\begin{lemma}\label{lem:ix-r-dist} For any distinct $x,y\in [u]$, 
   \begin{align}
      \Pr[i_x=0]&\le(1+r/2^b)/r\label{eq:ix=0}\\
      \Pr[i_x=i_y]&\leq \left(1+(r/2^b)^2\right)/r.\label{eq:ix=iy}
   \end{align}
\end{lemma}
\begin{proof}
   The proof of \eqref{eq:ix=0} is a simple calculation.
   Using \eqref{eq:prix0} and the fact $\ceil{2^{b-1}/r}\le(2^{b-1}+r-1)/r$ we have
   \begin{align*}
      \Pr[i_x=0]&\le (2(2^{b-1}+r-1)/r)-1)/(2^{b}-1)\\
                %&=((2^b+r-2)/r)/(2^b-1)\\
                &=\left(1+(r-1)/(2^b-1)\right)/r\\
                &\le\left(1+r/2^b\right)/r.
   \end{align*}
   The last inequality follows because $r<u<2^b$.

   % The proof of \ref{eq:ix=iy} follows from {\color{red}Thomas}.
   For \ref{eq:ix=iy},
   let $q=2^{b-1}$ and $p=1/(2q-1)$.
   We define $a\ge 0$ to be the smallest integer, such that $r\setminus q+a$.
   In particular this means 
   $\lceil q/r\rceil = (q+a)/r$ and
   $\lfloor q/r\rfloor = (q-r+a)/r$.

   We bound the sum
   $$
   \Pr[i_x=i_y]
   = \sum_{k=0}^{r-1} \Pr[i_x = k]^2
   $$
   by splitting into three cases:
   1) The case $i_x=0$, where $\Pr[i_x=0]=(2\ceil{q/r}-1)p$,
   2) the $r-a-1$ indices $j$ where $\Pr[i_x=j]=2\ceil{q/r}p$,
   and 3) the $a$ indices $j$ st. $\Pr[i_x=j]=2\floor{q/r}p$.
   \begin{align*}
      \Pr[i_x=i_y]
   &=
   (2p\ceil{ q/r}-p)^2 + (r-a-1) (2p \lceil q/r\rceil)^2 + (r-a) (2p \lfloor q/r \rfloor)^2
 \\&= ((4a+1)r+4(q+a)(q-a-1))p^2/r
 \\&\le (1 + (r^2-r)/(2q-1)^2) / r.
   \end{align*}
   The last inequality comes from maximizing over $a$, which yields $a=(r-1)/2$.

   The result now follows from
   \begin{align}
      (r^2-r)/(2q-1)^2
      \le
      (r-1/2)^2/(2q-1)^2
      \le
      (r/(2q))^2,
   \end{align}
   which holds exactly when $r\le q$.



\end{proof}
Lemma \ref{lem:ix-r-dist} above is all we need to know about the
marginal distribution of $i_x$. However, we also need a replacement
for Lemma \ref{lem:remove-si} for handling the sign-bit $s_x$.
\begin{lemma}\label{lem:remove-si-r-dist} Consider distinct keys
   $x_0,\ldots,x_{j - 1}$, $j\leq k$ and an expression $B=s_{x_0}A$ where $A$
   depends on $i_{x_0},\ldots,i_{x_{j - 1}}$ and $s_{x_1},\ldots,s_{x_{j - 1}}$ but not
   $s_{x_0}$. 
   Then
   \begin{equation}\label{eq:remove-si-r-dist}
      \E[s_xA]=\E[A \mid i_x=0]/p.
   \end{equation}
\end{lemma}
\begin{proof}
   The proof follows the same idea as that for Lemma \ref{lem:remove-si}.
   First we have
   \[\E[B]=\E_{h(x_0) \sim \unif([2^b]\setminus\{0\})}[B]=\E_{h(x_0) \sim \unif[2^b]}[B]2^b/p-\E[B \mid h(x_0)=0]/p.\]
   With $h(x_0)\sim \unif[2^b]$, the bit $a_{x_0}$ is uniform and 
   independent of $j_{x_0}$, so $s_{x_1}\in\{-1,1\}$ is uniform and 
   independent of $i_{x_0}$, and therefore 
   \[\E_{h(x_0) \sim \unif[2^b]}[s_{x_0}A]=0.\]
   Moreover, $h(x_0)=0$ implies $j_x={x_0}$, $i_{x_0}=0$, $a_{x_0}=0$,
   and $s_{x_0}=-1$,
   so 
   \[\E[s_{x_0}A]=-\E[s_{x_0}A \mid h(x_0)=0]/p=\E[A \mid i_{x_0}=0].\]
\end{proof}

From \Cref{lem:remove-si-r-dist} and \eqref{eq:ix=0} we have \nameref{prop:near-independence}
with $\Pr[i_x = 0] \le (1 + r/2^b)/r$, and \eqref{eq:ix=iy} implies that we have
$(1 + (r/2^b)^2)/r$-low collision probability. We can then use
\Cref{lem:count-mersenne} to prove the following result.
\begin{theorem}\label{thm:h-and-s-p-arb-r}
   Let $u$ be a power of two, $1 < r \le u/2$, and let $p=2^b-1>u$ be a
   Mersenne prime.
   Suppose with have a 4-universal hash function $h:[u]\to[2^b-1]$, e.g.,
   generated using \Cref{alg:Mersenne}. Suppose
   $i:[u]\to[r]$ and
   $s:[u]\to\{-1,1\}$ are constructed from $h$ as described in
   \Cref{alg:Mersenne-arb-r}. Using this $i$ and $s$ 
   in the Count Sketch Algorithm \ref{alg:count-sketch}, the second moment 
   estimate $X=\sum_{i\in[k]} C_i^2$ satisfies:
   \begin{align}
      \E[X] &= F_2+(F_1^2-F_2)/p^2, \label{eq:E-F2-p-arb-r}\\
      | \E[X] - F_2 | &\le F_2 (n - 1)/p^2, \label{eq:E-F2-p-com-arb-r}\\
      \Var[X]&< 2(1 + (r/2^b)^2)F_2^2/r.\label{eq:V-F2-p-arb-r}
   \end{align}
\end{theorem}

Now \Cref{lem:count-mersenne} give us \eqref{eq:E-F2-p-arb-r}
and \eqref{eq:E-F2-p-com-arb-r}. Furthermore, we have that
\begin{align*}
    \Var[X] 
        &\le 2F_2^2/r + F_2^2 (2\eps/r + 4(1 + \delta)n / (rp^2) + n^2/p^4 - 2 /(rn))
        \\&= 2(1 + (r/2^b)^2)F_2^2/r + F_2^2(4(1 + r/2^b)n/(r p^2) + n^2/p^4 - 2/(rn)) 
        \\&\le 2(1 + (r/2^b)^2)F_2^2/r + F_2^2(4(1 + r/p)n/(r p^2) + n^2/p^4 - 2/(rn)) .
\end{align*}

We know that $2 \le r \le u/2 \le (p + 1)/4$ and $n \le u$.
This implies that $p \ge 7$ and that $n/p \le u/p \le 4/7$.
If we can prove that $4(1 + r/p)n / (rp^2) + n^2/p^4 - 2 / (rn) \le 0$ then
we have the result. We have that
\begin{align*}
   4(1 + r/p)n / (rp^2) + n^2/p^4 - 2 / (rn)
      &= 4 n/(rp^2) + 4 n /(p^3) + n^2/p^4 - 2/(rn)
      \\&\le 4u/(rp^2) + 4u/(p^3) + u^2/p^4 - 2/(ru) .
\end{align*}
Again we note that $4u/(r p^2) - 2/(ru) = (2u^2 - p^2)/(u p^2 r) \le 0$
since $u \le (p + 1)/2$ so it maximized when $r = u/2$. We then get
that
\begin{align*}
   4u/(r p^2) + 4u/(p^3) + u^2/p^4 - 2/(ru)
      \le 8/p^2 + 4u/(p^3) + u^2/p^4 - 4/u^2 .
\end{align*}
We now use that $u/p \le (4/7)^2$ and get that
\begin{align*}
   8/p^2 + 4u/(p^3) + u^2/p^4 - 4/u^2 .
      \le (8 + 4 (4/7) + (4/7)^2 - 4 (7/4)^2)/p^2
      \le 0 .
\end{align*}
This finishes the proof of \eqref{eq:V-F2-p-arb-r} and thus also of \Cref{thm:h-and-s-p-arb-r}.

